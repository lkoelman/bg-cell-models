{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print date and time of script execution\n",
    "import datetime\n",
    "print(\"\\nNotebook executed at at {} in following directory:\".format(datetime.datetime.now()))\n",
    "%cd /home/luye/workspace/bgcellmodels/GilliesWillshaw/\n",
    "\n",
    "# print code version (hash of checked out version)\n",
    "print(\"\\nCode version info:\")\n",
    "!git log -1 # --format=\"%H\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib notebook\n",
    "\n",
    "# Bokeh for interactive plots\n",
    "from bokeh.io import push_notebook, output_notebook, show as bokeh_show\n",
    "from bokeh.plotting import figure as bokeh_figure\n",
    "output_notebook()\n",
    "\n",
    "# Import our analysis modules\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport optimize.bpop_analysis_stn\n",
    "%aimport optimize.bpop_analysis_pop\n",
    "\n",
    "resp_analysis = optimize.bpop_analysis_stn\n",
    "pop_analysis = optimize.bpop_analysis_pop\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 individuals, 100 generations IBEA dataset\n",
    "checkpoint_files = [\n",
    "    # ONE-SHOT OPTIMISATIONS\n",
    "    ['IBEA_100gen',\n",
    "     '/home/luye/cloudstore_m/simdata/marasco_folding/optimization_run_20171103_2/opt_checkpoints_cdf893c2.pkl',\n",
    "     '/home/luye/cloudstore_m/simdata/marasco_folding/optimization_run_20171103_2/opt_checkpoints_cdf893c2_settings_withparamsobjs.pkl'],\n",
    "    ['NSGA2_100gen',\n",
    "     '/home/luye/cloudstore_m/simdata/marasco_folding/optimization_run_20171103_1/opt_checkpoints_3210b868.pkl',\n",
    "     '/home/luye/cloudstore_m/simdata/marasco_folding/optimization_run_20171103_1/opt_checkpoints_3210b868_settings.pkl'],\n",
    "    ['IBEA_100gen_BACKGROUND',\n",
    "     '/home/luye/cloudstore_m/simdata/marasco_folding/optimization_run_20171106_1/opt_checkpoints_6b30ea0c.pkl',\n",
    "     '/home/luye/cloudstore_m/simdata/marasco_folding/optimization_run_20171106_1/opt_checkpoints_6b30ea0c_settings.pkl'],\n",
    "    ['IBEA_100gen_BACKGROUND_2',\n",
    "     '/home/luye/Documents/optimization_run_20171108_1/opt_checkpoints_aeee0fa8.pkl',\n",
    "     '/home/luye/Documents/optimization_run_20171108_1/opt_checkpoints_aeee0fa8_settings_withparamsobjs.pkl'],\n",
    "    # INCREMENTAL OPTIMISATIONS\n",
    "    ['INCR_REB_MINSYN',\n",
    "     '/home/luye/Documents/optimization_run_20171105_1/opt_checkpoints_28d1c4f6.pkl',\n",
    "     '/home/luye/Documents/optimization_run_20171105_1/opt_checkpoints_28d1c4f6_settings.pkl'],\n",
    "    ['INCR_BACKGROUND',\n",
    "     '/home/luye/Documents/optimization_run_20171106_2/opt_checkpoints_7b14ca54.pkl',\n",
    "     '/home/luye/Documents/optimization_run_20171106_2/opt_checkpoints_7b14ca54_settings.pkl'],\n",
    "]\n",
    "\n",
    "opt_data = pd.DataFrame(checkpoint_files, columns=['name', 'checkpoints_file', 'settings_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose optimisation to analyse\n",
    "opt_name = 'IBEA_100gen' # SETPARAM: optimisation run to analyse\n",
    "\n",
    "# from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "# import ipywidgets as widgets\n",
    "# def f(x):\n",
    "#     global opt_name\n",
    "#     opt_name = x\n",
    "# interact(f, x=opt_data['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = opt_data.index[opt_data['name'] == opt_name][0] # addres by value in field\n",
    "cp_file = opt_data['checkpoints_file'][idx]\n",
    "settings_file = opt_data['settings_file'][idx]\n",
    "\n",
    "print(\"Analysing data for {} from files:\\n{}\\n{}\".format(opt_name, cp_file, settings_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load logs file\n",
    "import cPickle as pickle\n",
    "\n",
    "# Old pickling method\n",
    "# with open(checkpoints_file, 'r') as f:\n",
    "#     checkpoint = pickle.load(f)\n",
    "#     # old_param_names = pickle.load(f)\n",
    "\n",
    "# New pickling method\n",
    "with open(cp_file, \"rb\") as f:\n",
    "    while True:\n",
    "        try:\n",
    "            checkpoint = pickle.load(f)\n",
    "        except EOFError:\n",
    "            break\n",
    "\n",
    "# Get variables\n",
    "hof = checkpoint['halloffame']\n",
    "log = checkpoint['logbook']\n",
    "pareto_front = checkpoint['paretofront']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load settings file\n",
    "with open(settings_file, 'r') as f:\n",
    "    opt_settings = pickle.load(f)\n",
    "    \n",
    "pp.pprint(opt_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation protocol responses\n",
    "\n",
    "- make a random validation protocol\n",
    "- set up models and params like in opt notebook\n",
    "- plot all responses like in l5pc_analysis.py\n",
    "- calculate scores\n",
    "- select based on scores\n",
    "    + write to pickle file: selected params so we can instantiate and run bagged opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributed logging\n",
    "from bgcellmodels.common import logutils\n",
    "\n",
    "# BluePyOpt\n",
    "import bluepyopt.ephys as ephys\n",
    "\n",
    "# Custom BluePyOpt modules\n",
    "from optimize.bpop_cellmodels import StnFullModel, StnReducedModel\n",
    "from optimize.bpop_protocols_stn import BpopProtocolWrapper\n",
    "import optimize.bpop_analysis_stn as resp_analysis\n",
    "import optimize.bpop_features_stn as features_stn\n",
    "\n",
    "# Physiology parameters\n",
    "from bgcellmodels.cellpopdata import StnModel\n",
    "from evalmodel.proto_common import StimProtocol\n",
    "\n",
    "CLAMP_PLATEAU = StimProtocol.CLAMP_PLATEAU\n",
    "CLAMP_REBOUND = StimProtocol.CLAMP_REBOUND\n",
    "MIN_SYN_BURST = StimProtocol.MIN_SYN_BURST\n",
    "SYN_BACKGROUND_HIGH = StimProtocol.SYN_BACKGROUND_HIGH\n",
    "VALIDATION = StimProtocol.SYN_BACKGROUND_LOW\n",
    "\n",
    "# Adjust verbosity of loggers\n",
    "logutils.setLogLevel('quiet', ['marasco', 'folding', 'redops', 'stn_protos', 'bpop_ext',\n",
    "                               'bluepyopt.ephys.parameters', 'bluepyopt.ephys.simulators',\n",
    "                               'bluepyopt.ephys.efeatures', 'bluepyopt.ephys.recordings'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose validation protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First add optimised protocols\n",
    "validation_protos = [StimProtocol.from_str(proto) for proto in opt_settings['protos_feats'].keys()]\n",
    "\n",
    "# Add validation protocol\n",
    "val_proto = VALIDATION\n",
    "validation_protos += [val_proto] # SETPARAM: choose the validation protocol\n",
    "opt_protos = [sp for sp in validation_protos if sp!=val_proto]\n",
    "\n",
    "# SETPARAM: copy possible protocol parameters from optimisation notebook\n",
    "proto_kwargs = {\n",
    "    CLAMP_REBOUND: {},\n",
    "    MIN_SYN_BURST: {},\n",
    "    VALIDATION: {\n",
    "        'impl_proto': val_proto,\n",
    "        'base_seed': 11,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Make all protocol data\n",
    "stimprotos_wrappers = {\n",
    "    stim_proto: BpopProtocolWrapper.make(stim_proto, **proto_kwargs[stim_proto]) \n",
    "        for stim_proto in validation_protos\n",
    "}\n",
    "\n",
    "# Collect al frozen mechanisms and parameters required for protocols to work\n",
    "all_proto_mechs, all_proto_params = BpopProtocolWrapper.all_mechs_params(stimprotos_wrappers.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run protocols using full model to get responses\n",
    "full_model = StnFullModel(\n",
    "                name\t\t= 'StnGillies',\n",
    "                mechs\t\t= all_proto_mechs,\n",
    "                params\t\t= all_proto_params)\n",
    "\n",
    "# Set up simulation\n",
    "nrnsim = ephys.simulators.NrnSimulator(dt=0.025, cvode_active=False)\n",
    "\n",
    "# full_responses = wrapper.ephys_protocol.run(\n",
    "#                         cell_model\t\t= full_model, \n",
    "#                         param_values\t= {},\n",
    "#                         sim\t\t\t\t= nrnsim,\n",
    "#                         isolate\t\t\t= True)\n",
    "\n",
    "full_resp_dict = resp_analysis.run_proto_responses(\n",
    "                        full_model,\n",
    "                        [p.ephys_protocol for p in stimprotos_wrappers.values()])\n",
    "\n",
    "# Put in same format as evaluator.evaluate(individual)\n",
    "full_responses = {}\n",
    "for stimproto, responses in full_resp_dict.iteritems():\n",
    "    full_responses.update(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot full model responses\n",
    "resp_analysis.plot_proto_responses(full_resp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make objectives\n",
    "\n",
    "Make features + weights to put into singleton objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Optimised objectives ######################################################\n",
    "opt_objectives = opt_settings['objectives_ordered']\n",
    "if isinstance(opt_objectives, dict):\n",
    "    opt_features = [o.features[0] for o in opt_objectives.values()]\n",
    "else:\n",
    "    opt_features = [o.features[0] for o in opt_objectives]\n",
    "\n",
    "# 2. Validation objectives #####################################################\n",
    "\n",
    "# Make EFEL feature objects = dict(StimProtocol : dict(feature_name : tuple(efeature, weight)))\n",
    "stimprotos_feats = features_stn.make_opt_features([stimprotos_wrappers[p] for p in [val_proto]])\n",
    "\n",
    "# Convert to list(EFeature) and list(weight)\n",
    "val_features, val_weights = features_stn.all_features_weights(stimprotos_feats.values())\n",
    "\n",
    "# Calculate targets only for validation objectives (already saved in exp_mean for optimised objectives)\n",
    "features_stn.calc_feature_targets(stimprotos_feats, full_resp_dict)\n",
    "\n",
    "# 3. Merge them ################################################################\n",
    "all_features = opt_features + val_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get training & validation errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make free parameters (locations etc, not values)\n",
    "opt_param_names = opt_settings['opt_param_names'] # same order as in individuals\n",
    "opt_free_params = opt_settings['free_params'].values()\n",
    "\n",
    "# Create reduced model and get parameters\n",
    "red_model = StnReducedModel(\n",
    "                name\t\t= 'StnFolded',\n",
    "                fold_method\t= 'marasco',\n",
    "                num_passes\t= 7,\n",
    "                mechs\t\t= all_proto_mechs,\n",
    "                params\t\t= all_proto_params + opt_free_params)\n",
    "\n",
    "# Make validation objectives calculators\n",
    "all_objectives = [ephys.objectives.SingletonObjective(f.name, f) for f in all_features]\n",
    "fitcalc = ephys.objectivescalculators.ObjectivesCalculator(all_objectives)\n",
    "\n",
    "# Make evaluator to evaluate model using objective calculator\n",
    "opt_ephys_protos = {s.name: w.ephys_protocol for s,w in stimprotos_wrappers.iteritems()}\n",
    "\n",
    "nrnsim = ephys.simulators.NrnSimulator(dt=0.025, cvode_active=False)\n",
    "\n",
    "from optimize.bpop_extensions import CellEvaluatorCaching\n",
    "evaluator = CellEvaluatorCaching(\n",
    "                    cell_model\t\t\t= red_model,\n",
    "                    param_names\t\t\t= opt_param_names, # fitted parameters (same order as saved individuals!)\n",
    "                    fitness_protocols\t= opt_ephys_protos,\n",
    "                    fitness_calculator\t= fitcalc,\n",
    "                    sim\t\t\t\t\t= nrnsim,\n",
    "                    isolate_protocols\t= True)\n",
    "\n",
    "# Save responses that are evaluated\n",
    "import os.path\n",
    "folder, tail = os.path.split(cp_file)\n",
    "newtail = 'response_ind_'\n",
    "evaluator.set_responses_filename(folder, newtail)\n",
    "ind_resp_file_prefix = os.path.join(folder, newtail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from ipyparallel import Client\n",
    "import socket\n",
    "\n",
    "# Create a connection to the server\n",
    "rc = Client() # if profile specified: searches JSON file in ~/.ipython/profile_name\n",
    "print('Using ipyparallel with %d engines' % len(rc))\n",
    "\n",
    "# Create a view of all the workers (ipengines)\n",
    "lview = rc.load_balanced_view()\n",
    "host_names = lview.apply_sync(socket.gethostname) # run gethostname on all ipengines\n",
    "if isinstance(host_names, str):\n",
    "    host_names = [host_names]\n",
    "\n",
    "def map_func(func, *sequences):\n",
    "    \"\"\"\n",
    "    @param sequences    sequences of matching length with sequence i\n",
    "                        containing the i-th argument for func\n",
    "    \"\"\"\n",
    "    start_time = datetime.now()\n",
    "    ret = lview.map_sync(func, *sequences)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate validation protocols using all individuals\n",
    "eval_inds = hof\n",
    "all_ind_scores = map_func(evaluator.evaluate_with_lists, eval_inds, range(len(eval_inds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the non-optimised model (all default params)\n",
    "unopt_ind = [opt_settings['free_params'][p].value for p in opt_param_names]\n",
    "unopt_ind\n",
    "unopt_scores = map_func(evaluator.evaluate_with_lists, [unopt_ind], ['unopt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape individuals into matrix with each individual's scores represented by a row\n",
    "ind_scores_as_rows = np.array(all_ind_scores + unopt_scores)\n",
    "obj_names = [o.name for o in all_objectives]\n",
    "ind_scores_data = pd.DataFrame(ind_scores_as_rows, columns=obj_names)\n",
    "\n",
    "# Select scores on validation protocol only\n",
    "val_obj_names = [o.name for o in all_objectives if val_proto.name in o.name]\n",
    "ind_val_data = ind_scores_data[val_obj_names]\n",
    "\n",
    "# Select scores on optimized protocols only\n",
    "opt_obj_names = [o.name for o in all_objectives if not o.name in val_obj_names]\n",
    "ind_opt_data = ind_scores_data[opt_obj_names]\n",
    "\n",
    "print(\"\\nObjectives used in optimisation:\")\n",
    "pp.pprint(opt_obj_names)\n",
    "print(\"\\nObjectives used in validation:\")\n",
    "pp.pprint(val_obj_names)\n",
    "\n",
    "print(\"\\nScores for first individuals in hall of fame:\")\n",
    "print(ind_opt_data.iloc[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate training & validation errors (scores)\n",
    "sum_opt_scores = ind_opt_data.sum(axis=1)\n",
    "sum_val_scores = ind_val_data.sum(axis=1)\n",
    "i_nofail = np.where(sum_val_scores < 250.0)[0]\n",
    "\n",
    "\n",
    "xdata = sum_opt_scores.index[i_nofail]\n",
    "ydata = sum_opt_scores.values[i_nofail]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.barplot(x=xdata, y=ydata)\n",
    "# ax.bar(sum_opt_scores.index, sum_opt_scores.values)\n",
    "ax.set_title('Sum of optimisation errors')\n",
    "ax.set_ylabel('$\\sum w_i e_i$')\n",
    "ax.set_yscale('log')\n",
    "# ax.set_ylim((int(min(sum_opt_scores.values)), max(sum_opt_scores.values)))\n",
    "# yticks = np.arange(int(min(sum_opt_scores.values)), max(sum_opt_scores.values), .1)\n",
    "# ax.set_yticks(yticks, minor=True)\n",
    "# ax.tick_params(reset=True, axis='y', which='minor', direction='in', width=2.0)\n",
    "# import matplotlib.ticker as ticker\n",
    "# ax.yaxis.set_minor_formatter(ticker.FormatStrFormatter('%0.1f'))\n",
    "# ysubticks = np.arange(2.1, 9, .1)\n",
    "# ax.set_yscale('log', ysubs=ysubticks)\n",
    "\n",
    "\n",
    "\n",
    "# Plot sum of validation errors\n",
    "\n",
    "xdata = sum_val_scores.index[i_nofail]\n",
    "ydata = sum_val_scores.values[i_nofail]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.barplot(x=xdata, y=ydata)\n",
    "ax.set_title('Sum of validation errors')\n",
    "ax.set_ylabel('$\\sum w_i e_i$')\n",
    "# ax.set_yticks(np.arange(1, 250, 1))\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylim((5, 35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each validation error for each individual\n",
    "f, all_ax = plt.subplots(len(val_obj_names), 1, sharex=True)\n",
    "for i, ax in enumerate(all_ax):\n",
    "    xdata = ind_val_data.index[i_nofail]\n",
    "    ydata = ind_val_data[ind_val_data.columns[i]].values[i_nofail]\n",
    "    sns.barplot(x=xdata, y=ydata, ax=ax)\n",
    "    # ax.bar(ind_val_data.index, ydata)\n",
    "    ax.set_title(ind_val_data.columns[i])\n",
    "    ax.set_ylabel('$w_i e_i$')\n",
    "    ax.set_ylim((0, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select individuals that perform best on validaton protocol\n",
    "target_obj = val_obj_names[1] # SETPARAM: objective to sort on\n",
    "sorted_index = np.argsort(ind_val_data[target_obj].values)\n",
    "best_ids_validated = sorted_index\n",
    "\n",
    "print(\"Objective used for ranking: {}\".format(target_obj))\n",
    "print('\\nIndices of best ranked individuals:\\n{}'.format(sorted_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load responses of best individuals\n",
    "num_best = len(hof)\n",
    "ind_responses = []\n",
    "for ind_idx in range(len(hof)):\n",
    "    \n",
    "    # Load saved responses\n",
    "    resp_file = ind_resp_file_prefix + str(ind_idx)\n",
    "    with open(resp_file, 'rb') as f:\n",
    "        responses = pickle.load(f)\n",
    "    \n",
    "    ind_responses.append(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add response of default model\n",
    "with open(ind_resp_file_prefix+'unopt', 'rb') as f:\n",
    "    ind_responses.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare raster plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get spike times\n",
    "import efel\n",
    "\n",
    "def get_peaktimes(tvresp, proto):\n",
    "    \"\"\"\n",
    "    Function to extract peak times from TimeVoltageResponse\n",
    "    \"\"\"\n",
    "    efel.reset()\n",
    "    efel.setThreshold(-20.0) # eFEL default value\n",
    "    \n",
    "    # Prepare trace\n",
    "    efel_trace = {\n",
    "        'T': tvresp['time'],\n",
    "        'V': tvresp['voltage'],\n",
    "        'stim_start': [proto.response_interval[0]],\n",
    "        'stim_end': [proto.response_interval[1]],\n",
    "    }\n",
    "\n",
    "    # Calculate spike times from response\n",
    "    values = efel.getFeatureValues([efel_trace], ['peak_time'], raise_warnings=True)\n",
    "    return values[0]['peak_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get spike times for full model\n",
    "val_response = full_resp_dict[val_proto.name]\n",
    "val_wrapper = stimprotos_wrappers[val_proto]\n",
    "full_spiketimes = get_peaktimes(val_response.items()[0][1], val_wrapper)\n",
    "\n",
    "# Get spike times for all individuals\n",
    "ind_spiketimes = []\n",
    "for i_hof in range(len(hof) + 1):\n",
    "    \n",
    "    # Load saved responses\n",
    "#     resp_file = ind_resp_file_prefix + str(i_hof)\n",
    "#     with open(resp_file, 'rb') as f:\n",
    "#         responses = pickle.load(f)\n",
    "        \n",
    "    # Get previously loaded response\n",
    "    responses = ind_responses[i_hof]\n",
    "    \n",
    "    # Calculate spike times\n",
    "    val_response = next((v for k,v in responses.items() if val_proto.name in k))\n",
    "    peak_times = get_peaktimes(val_response, val_wrapper)\n",
    "    ind_spiketimes.append(peak_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bgcellmodels.common import analysis\n",
    "import collections\n",
    "\n",
    "all_spk = collections.OrderedDict()\n",
    "for i_hof in best_ids_validated:\n",
    "    # Save using index in hof (fall of fame)\n",
    "    if i_hof >= len(hof):\n",
    "        label = 'def'\n",
    "    else:\n",
    "        label = 'ind{}'.format(i_hof)\n",
    "    all_spk[label] = ind_spiketimes[i_hof]\n",
    "\n",
    "# create X and Y data for scatter plot\n",
    "spike_labels = list(reversed(all_spk.keys()))\n",
    "spike_vecs = [all_spk[label] for label in spike_labels]\n",
    "x_data = np.concatenate(spike_vecs) # X data is concatenated spike times\n",
    "y_data = np.concatenate([np.zeros_like(vec)+j for j, vec in enumerate(spike_vecs)]) # Y-data is trace IDs\n",
    "\n",
    "# Filter data within given time interval\n",
    "timeRange = val_wrapper.response_interval\n",
    "mask = (x_data > timeRange[0]) & (x_data < timeRange[1])\n",
    "x_data = x_data[mask]\n",
    "y_data = y_data[mask]\n",
    "\n",
    "# Plot data as scatter plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x_data, y_data, s=4, c='b', lw=0, marker='.') # marker=',' is thicker\n",
    "ax.plot(full_spiketimes, np.zeros_like(full_spiketimes)+len(spike_vecs), c='r', lw=0, markersize=2, marker='.')\n",
    "\n",
    "# Axes\n",
    "ax.set_xlim(timeRange)\n",
    "ax.grid(True, axis='x')\n",
    "\n",
    "plt.yticks(range(len(spike_labels)), spike_labels, rotation='horizontal')\n",
    "ax.set_xlabel('time (ms)')\n",
    "ax.set_title('Validation protocol spike trains', loc='center')\n",
    "\n",
    "fig.subplots_adjust(left=0.15) # Tweak spacing to prevent clipping of tick-labels\n",
    "fig.set_figheight(0.2*len(all_spk))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect best individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_responses(ind_responses, full_responses=None, plot_kws=None):\n",
    "    \"\"\"\n",
    "    Plot responses dict returned by an EphysProtocol\n",
    "\n",
    "    @param\tproto_responses\t\tdict {str: responses.TimeVoltageResponse}\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(len(ind_responses))\n",
    "    try:\n",
    "        iter(axes)\n",
    "    except TypeError:\n",
    "        axes = [axes]\n",
    "\n",
    "    if plot_kws is None:\n",
    "        plot_kws = {}\n",
    "    if full_responses is None:\n",
    "        full_responses = {}\n",
    "    \n",
    "    for index, resp_name in enumerate(sorted(ind_responses.keys())):\n",
    "        ax = axes[index]\n",
    "        ax.set_title(resp_name, color='g')\n",
    "        \n",
    "        # Mark validation protocol\n",
    "        if val_proto.name in ax.title.get_text():\n",
    "            ax.title.set_color('r')\n",
    "        \n",
    "        # Plot target responses (lowest z-index)\n",
    "        if resp_name in full_responses:\n",
    "            response = full_responses[resp_name]\n",
    "            axes[index].plot(response['time'], response['voltage'], 'r-', linewidth=1, label='full')\n",
    "        \n",
    "        # Plot individual response\n",
    "        response = ind_responses[resp_name]\n",
    "        axes[index].plot(response['time'], response['voltage'], label='reduced', **plot_kws)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Vm of best optimised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks_toplot = range(3)\n",
    "for rank in ranks_toplot:\n",
    "    ind_id = rank\n",
    "    \n",
    "    print(\"Hall of fame index: {}\".format(ind_id))\n",
    "    print(\"Validation ranking index: {}\\n\".format(np.where(best_ids_validated==ind_id)[0]))\n",
    "    \n",
    "    # Print model parameters\n",
    "    ind_param_dict = {pname: hof[ind_id][i] for i,pname in enumerate(opt_param_names)}\n",
    "    pp.pprint(ind_param_dict)\n",
    "    \n",
    "    # Print errors\n",
    "    print(\"\\nOptimisation errors:\")\n",
    "    print(ind_opt_data.iloc[ind_id])\n",
    "    print(\"\\nValidation errors:\")\n",
    "    print(ind_val_data.iloc[ind_id])\n",
    "    \n",
    "    # Plot optimised & validation responses\n",
    "    fig, axes = plot_responses(ind_responses[ind_id], full_responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Vm of best validated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks_toplot = range(3)\n",
    "for val_rank in ranks_toplot:\n",
    "    ind_id = best_ids_validated[val_rank]\n",
    "    \n",
    "    print(\"Hall of fame index: {}\".format(ind_id))\n",
    "    print(\"Validation ranking index: {}\\n\".format(val_rank))\n",
    "    \n",
    "    # Print model parameters\n",
    "    ind_param_dict = {pname: hof[ind_id][i] for i,pname in enumerate(opt_param_names)}\n",
    "    pp.pprint(ind_param_dict)\n",
    "    \n",
    "    # Print errors\n",
    "    print(\"\\nOptimisation errors:\")\n",
    "    print(ind_opt_data.iloc[ind_id])\n",
    "    print(\"\\nValidation errors:\")\n",
    "    print(ind_val_data.iloc[ind_id])\n",
    "    \n",
    "    # Plot optimised & validation responses\n",
    "    fig, axes = plot_responses(ind_responses[ind_id], full_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "886px",
    "left": "0px",
    "right": "1431px",
    "top": "67px",
    "width": "249px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
