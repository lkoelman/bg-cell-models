{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synaptic stimulation protocols tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable interactive plots with backend 'notebook'\n",
    "%matplotlib notebook\n",
    "# %matplotlib inline\n",
    "# Enable plotting of figures after exceptions\n",
    "import bgcellmodels.common.jupyterutil as jupyterutil\n",
    "jupyterutil.notebook_show_figs_after_exception()\n",
    "\n",
    "# print code version (hash of checked out version)\n",
    "!git log -1 --format=\"%H\"\n",
    "\n",
    "# print date and time of script execution\n",
    "import os, datetime\n",
    "gillies_model_dir = '../../../GilliesWillshaw'\n",
    "os.chdir(gillies_model_dir)\n",
    "print(\"\\nNotebook executed at {} in following directory:\\n{}\".format(\n",
    "        datetime.datetime.now(), os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import optimization module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python standard library\n",
    "import pickle, pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "from bgcellmodels.common import logutils\n",
    "\n",
    "# BluePyOpt\n",
    "import bluepyopt.ephys as ephys\n",
    "\n",
    "# Custom BluePyOpt modules\n",
    "from cersei_cellmodel import StnCellReduced\n",
    "from optimize.bpop_protocols_stn import BpopProtocolWrapper\n",
    "from optimize.bpop_analysis_stn import (\n",
    "    run_proto_responses, plot_proto_responses, \n",
    "    save_proto_responses, load_proto_responses,\n",
    "    plot_responses\n",
    ")\n",
    "\n",
    "import optimize.bpop_features_stn as features_stn\n",
    "# %load_ext autoreload\n",
    "# %autoreload 1\n",
    "# %aimport optimize.bpop_features_stn as features_stn\n",
    "\n",
    "# Physiology parameters\n",
    "from evalmodel.cellpopdata import StnModel\n",
    "from evalmodel.proto_common import StimProtocol\n",
    "SP = StimProtocol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust verbosity of loggers\n",
    "logutils.setLogLevel('quiet', ['marasco', 'folding', 'redops', \n",
    "                               'bluepyopt.ephys.parameters', 'bluepyopt.ephys.recordings'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Model\n",
    "## Create Protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protocols to use for optimisation\n",
    "opt_proto = SP.SYN_BACKGROUND_LOW\n",
    "proto_kwargs = { # SETPARAM: extra keyword arguments for validation protocol\n",
    "    'impl_proto': opt_proto,\n",
    "    'base_seed': 8,\n",
    "    'num_syn_gpe': 12,\n",
    "}\n",
    "stimprotos_wrappers = {\n",
    "    SP.SYN_BACKGROUND_LOW: BpopProtocolWrapper.make(opt_proto, **proto_kwargs)\n",
    "}\n",
    "proto_wrappers = stimprotos_wrappers.values()\n",
    "opt_stim_protocols = stimprotos_wrappers.keys()\n",
    "ephys_protos = [p.ephys_protocol for p in proto_wrappers]\n",
    "\n",
    "# Collect al frozen mechanisms and parameters required for protocols to work\n",
    "proto_mechs, proto_params = BpopProtocolWrapper.all_mechs_params(proto_wrappers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Inspect model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_model = StnCellReduced(\n",
    "                reduction_method = None,\n",
    "                name\t\t= 'StnGillies',\n",
    "                mechs\t\t= proto_mechs,\n",
    "                params\t\t= proto_params)\n",
    "\n",
    "# Instantiate model\n",
    "nrnsim = ephys.simulators.NrnSimulator(dt=0.025, cvode_active=False)\n",
    "param_values = {}\n",
    "\n",
    "# Instantiate cell model and stimulation protocol\n",
    "cell_model.freeze(param_values)\n",
    "ephys_protos[0].pre_model_instantiate(cell_model=cell_model, sim=nrnsim)\n",
    "cell_model.instantiate(sim=nrnsim)\n",
    "ephys_protos[0].post_model_instantiate(cell_model=cell_model, sim=nrnsim)\n",
    "\n",
    "# Start NEURON GUI\n",
    "from neuron import gui\n",
    "# Now you can inspect the model in NEURON GUI: \n",
    "# Tools > ModelView > Soma > Point Processes > GABAsyn & GLUsyn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run protocols using full model to get responses\n",
    "full_model = StnCellReduced(\n",
    "                reduction_method = None,\n",
    "                name\t\t= 'StnGillies',\n",
    "                mechs\t\t= proto_mechs,\n",
    "                params\t\t= proto_params)\n",
    "\n",
    "nrnsim = ephys.simulators.NrnSimulator(dt=0.025, cvode_active=False)\n",
    "\n",
    "# Simulate protocols\n",
    "full_responses = {}\n",
    "for e_proto in ephys_protos:\n",
    "    \n",
    "    # Make sure recording functions are executes\n",
    "    e_proto.record_contained_traces = True\n",
    "    \n",
    "    full_responses[e_proto.name] = e_proto.run(\n",
    "                                        cell_model\t\t= full_model, \n",
    "                                        param_values\t= {},\n",
    "                                        sim\t\t\t\t= nrnsim,\n",
    "                                        isolate\t\t\t= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plot_proto_responses(full_responses)\n",
    "for proto in ephys_protos:\n",
    "    proto.plot_contained_traces()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Feature Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make EFEL feature objects\n",
    "stimprotos_feats = features_stn.make_opt_features(proto_wrappers)\n",
    "\n",
    "# Calculate target values from full model responses\n",
    "features_stn.calc_feature_targets(stimprotos_feats, full_responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduced Model\n",
    "## Make Protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protocols to use for optimisation\n",
    "# same as full model\n",
    "# opt_stim_protocols = [SP.SYN_BACKGROUND_HIGH]\n",
    "\n",
    "# Make all protocol data\n",
    "# proto_wrappers = [BpopProtocolWrapper.make(p) for p in opt_stim_protocols]\n",
    "# ephys_protos = [p.ephys_protocol for p in proto_wrappers]\n",
    "\n",
    "# Collect al frozen mechanisms and parameters required for protocols to work\n",
    "# proto_mechs, proto_params = BpopProtocolWrapper.all_mechs_params(proto_wrappers)\n",
    "\n",
    "# Protocols to use for optimisation\n",
    "stimprotos_wrappers = {\n",
    "    SP.SYN_BACKGROUND_LOW: BpopProtocolWrapper.make(opt_proto, **proto_kwargs)\n",
    "}\n",
    "proto_wrappers = stimprotos_wrappers.values()\n",
    "opt_stim_protocols = stimprotos_wrappers.keys()\n",
    "ephys_protos = [p.ephys_protocol for p in proto_wrappers]\n",
    "\n",
    "# Collect al frozen mechanisms and parameters required for protocols to work\n",
    "proto_mechs, proto_params = BpopProtocolWrapper.all_mechs_params(proto_wrappers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Reduced Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reduced model and get parameters\n",
    "red_model = StnCellReduced(\n",
    "                reduction_method='BushSejnowski',\n",
    "                name='StnFolded',\n",
    "                mechs=proto_mechs,\n",
    "                params=proto_params)\n",
    "\n",
    "nrnsim = ephys.simulators.NrnSimulator(dt=0.025, cvode_active=False)\n",
    "\n",
    "# Simulate protocols\n",
    "red_responses = {}\n",
    "for e_proto in ephys_protos:\n",
    "    \n",
    "    # Make sure recording functions are executes\n",
    "    e_proto.record_contained_traces = True\n",
    "    \n",
    "    # NOTE: isolate=False only if model not previously build\n",
    "    red_responses[e_proto.name] = e_proto.run(\n",
    "                                        cell_model\t\t= red_model, \n",
    "                                        param_values\t= {},\n",
    "                                        sim\t\t\t\t= nrnsim,\n",
    "                                        isolate\t\t\t= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plot_proto_responses(red_responses)\n",
    "for proto in ephys_protos:\n",
    "    proto.plot_contained_traces()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Feature Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust exp_std in efeature references\n",
    "for stimproto, featdict in stimprotos_feats.iteritems():\n",
    "    for efeat, weight in featdict.values():\n",
    "\n",
    "        # NOTE: score = distance = sum(feat[i] - exp_mean) / N / exp_std  => so exp_std determines weight\n",
    "        score = efeat.calculate_score(red_responses[stimproto.name]) # exp_std is 1.0, so score will be numerator\n",
    "#         efeat.exp_std = score / weight # divide numerator so it has desired weight\n",
    "\n",
    "        print('Calculates {} score: {}'.format(efeat.name, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate ISI Voltage distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimize.efeatures_fast_numba import calc_ISI_voltage_distance_dt_equal\n",
    "import efel\n",
    "\n",
    "def get_ISI_Vdist(tvresp1, tvresp2, proto):\n",
    "    \"\"\"\n",
    "    Function to extract peak times from TimeVoltageResponse\n",
    "    \"\"\"\n",
    "    feat_vals = []\n",
    "    efel_traces = []\n",
    "    \n",
    "    for tvresp in [tvresp1, tvresp2]:\n",
    "        # Prepare trace\n",
    "        efel_trace = {\n",
    "            'T': tvresp['time'],\n",
    "            'V': tvresp['voltage'],\n",
    "            'stim_start': [proto.response_interval[0]],\n",
    "            'stim_end': [proto.response_interval[1]],\n",
    "        }\n",
    "        efel_traces.append(efel_trace)\n",
    "\n",
    "        # Calculate required features\n",
    "        efel_feats = ['AP_begin_indices', 'AP_end_indices']\n",
    "        feat_values = efel.getFeatureValues(\n",
    "            [efel_trace],\n",
    "            efel_feats,\n",
    "            raise_warnings=True\n",
    "        )\n",
    "        feat_vals.append(feat_values)\n",
    "\n",
    "    # Compute distance function\n",
    "    tar_AP_begin    = feat_vals[0][0]['AP_begin_indices']\n",
    "    tar_AP_end      = feat_vals[0][0]['AP_end_indices']\n",
    "    tar_Vm          = efel_traces[0]['V'].values\n",
    "    tar_dt          = efel_traces[0]['T'][1] - efel_traces[0]['T'][0]\n",
    "\n",
    "    cur_AP_begin    = feat_vals[1][0]['AP_begin_indices']\n",
    "    cur_AP_end      = feat_vals[1][0]['AP_end_indices']\n",
    "    cur_Vm          = efel_traces[1]['V'].values # pandas.Series to numpy.ndarray\n",
    "    cur_dt          = efel_traces[1]['T'][1] - efel_traces[1]['T'][0]\n",
    "\n",
    "    dt_equal = abs(tar_dt-cur_dt) <= 0.00001\n",
    "    if not dt_equal:\n",
    "        raise Exception(\"ISI voltage distance only implemented for traces calculated with equal time step (dt_old={}, dt_new={}).\".format(tar_dt, cur_dt))\n",
    "\n",
    "    if not all([np.issubdtype(v.dtype, int) for v in tar_AP_begin, tar_AP_end, cur_AP_begin, cur_AP_end]):\n",
    "        logger.warning(\"Calculation of AP indices failed\")\n",
    "        efel.reset()\n",
    "        return float('NaN')\n",
    "\n",
    "    return calc_ISI_voltage_distance_dt_equal(\n",
    "                            tar_Vm, cur_Vm, \n",
    "                            tar_AP_begin, cur_AP_begin,\n",
    "                            tar_AP_end, cur_AP_end,\n",
    "                            proto.response_interval[0], proto.response_interval[1], tar_dt)\n",
    "\n",
    "resp1 = full_responses.items()[0][1]\n",
    "resp2 = red_responses.items()[0][1]\n",
    "dist = get_ISI_Vdist(resp1.items()[0][1], resp2.items()[0][1], proto_wrappers[0])\n",
    "print dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate PSTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport bgcellmodels.common.analysis\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import efel; efel.reset()\n",
    "\n",
    "resp_dict = red_responses[opt_stim_protocols[0].name]\n",
    "TVresp = resp_dict.items()[0][1]\n",
    "stim_start, stim_end = 300.0, 1800.0\n",
    "\n",
    "efel_trace = {\n",
    "    'T': TVresp['time'],\n",
    "    'V': TVresp['voltage'],\n",
    "    'stim_start': [stim_start],\n",
    "    'stim_end': [stim_end],\n",
    "}\n",
    "\n",
    "# Get spike times using eFEL\n",
    "efel_feat = 'peak_time'\n",
    "feat_vals = efel.getFeatureValues(\n",
    "    [efel_trace],\n",
    "    [efel_feat],\n",
    "    raise_warnings = True\n",
    ")\n",
    "resp_spike_times = feat_vals[0][efel_feat]\n",
    "print(type(resp_spike_times), resp_spike_times)\n",
    "\n",
    "# Compute psth/rates\n",
    "\n",
    "bin_width = 50.0\n",
    "min_spk = 2\n",
    "\n",
    "psth1 = common.analysis.nrn_sum_psth(\n",
    "                [resp_spike_times], \n",
    "                stim_start, stim_end,\n",
    "                binwidth=bin_width).as_numpy()\n",
    "\n",
    "rates1 = common.analysis.nrn_avg_rate_adaptive(\n",
    "                [resp_spike_times], \n",
    "                stim_start, stim_end,\n",
    "                binwidth=bin_width,\n",
    "                minsum=min_spk).as_numpy()\n",
    "\n",
    "print(psth1)\n",
    "print(rates1)\n",
    "print('Exptected num bins = (tstop-tstart)/binwidth + 2 = {}'.format(int((stim_end-stim_start)/bin_width) + 2))\n",
    "print('Got num bins: {}'.format(psth1.size))\n",
    "\n",
    "\n",
    "psth2 = common.analysis.numpy_sum_psth(\n",
    "                [resp_spike_times], \n",
    "                stim_start, stim_end,\n",
    "                binwidth=bin_width)\n",
    "\n",
    "rates2 = common.analysis.numpy_avg_rate_simple(\n",
    "                [resp_spike_times], \n",
    "                stim_start, stim_end,\n",
    "                bin_width)\n",
    "\n",
    "print(psth2)\n",
    "print(rates2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot psth/rates\n",
    "plt.figure()\n",
    "plt.plot(stim_start + np.arange(0, psth.size)*(bin_width/2), psth)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(stim_start + np.arange(0, rates.size)*(bin_width/2), rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "845px",
    "left": "0px",
    "right": "1420px",
    "top": "67px",
    "width": "260px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
